{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 02.14.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1: Implementing Sentiment Analysis\n",
    " \n",
    "\n",
    "\n",
    "In this lab, you will develop a solution to perform sentiment analysis on the Internet Movie Database (IMDB) dataset.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Evaluate machine learning (ML) algorithms that are used in natural language processing (NLP) for sentiment analysis\n",
    "- Create a solution to a sentiment analysis business problem.\n",
    "\n",
    "## Introducing the business scenario\n",
    "\n",
    "In this lab, you will play the role of a data scientist on a small development team. The organization that you work for maintains a website of movie reviews. A key customer feature was identified: to provide an overall *Smiley Face* (positive inference) or *Sad Face* (negative inference) for a particular movie based on the number of its positive and negative reviews. You will develop an ML solution that developers can use to create an inference for a movie review. You will need to analyze the review and indicate if it is positive or negative.\n",
    "\n",
    "To help with this task, you have access to a dataset that contains the raw text of 50,000 movie reviews. These reviews have been labeled either as positive or negative.\n",
    "\n",
    "About this dataset\n",
    "The Large Movie Review Dataset is a collection of highly polar movie reviews. This data supports work in the following paper:\n",
    "\n",
    "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. \"Learning Word Vectors for Sentiment Analysis.\" Presented at the 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011), Portland, Oregon, USA, June 2011. http://ai.stanford.edu/~amaas/data/sentiment/.\n",
    "\n",
    "The dataset contains a single text field containing the review. The dataset is labeled either positive (1) or negative (0).\n",
    "\n",
    "The dataset contains the following features:\n",
    "\n",
    "text: Text of the review\n",
    "label: Whether the review is positive or negative (1 or 0)\n",
    "\n",
    "## Lab steps\n",
    "\n",
    "To complete this lab, you will follow these steps:\n",
    "\n",
    "1. [Installing packages](#1.-Installing-packages)\n",
    "2. [Reading the dataset](#2.-Reading-the-dataset)\n",
    "3. [Performing exploratory data analysis](#3.-Performing-exploratory-data-analysis)\n",
    "4. [Running the first pass: Minimal processing](#4.-Running-the-first-pass:-Minimal-processing)\n",
    "5. [Running the second pass: Normalizing the text](#5.-Running-the-second-pass:-Normalizing-the-text)\n",
    "6. [Tuning hyperparameters](#6.-Tuning-hyperparameters)\n",
    "7. [Using BlazingText](#7.-Using-BlazingText)\n",
    "8. [Using-Amazon Comprehend](#8.-Using-Amazon-Comprehend)\n",
    "\n",
    "## Submitting your work\n",
    "\n",
    "1. In the lab console, choose **Submit** to record your progress and when prompted, choose **Yes**.\n",
    "\n",
    "1. If the results don't display after a couple of minutes, return to the top of the lab instructions and choose **Grades**.\n",
    "\n",
    "**Tip:** You can submit your work multiple times. After you change your work, choose **Submit** again. Your last submission is what will be recorded for this lab.\n",
    "\n",
    "1. To find detailed feedback on your work, choose **Details** followed by **View Submission Report**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing packages\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "Start by updating and installing the packages that you will use in the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.17)\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.34.29-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore==1.35.29 (from awscli)\n",
      "  Downloading botocore-1.35.29-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awscli) (0.16)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awscli) (0.10.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awscli) (6.0.1)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awscli) (0.4.6)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore==1.35.29->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore==1.35.29->awscli) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore==1.35.29->awscli) (2.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.35.29->awscli) (1.16.0)\n",
      "Downloading awscli-1.34.29-py3-none-any.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.35.29-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, awscli\n",
      "Successfully installed awscli-1.34.29 botocore-1.35.29\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "Successfully installed pip-24.2\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.35.17)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.35.29-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.29 in /home/ec2-user/.local/lib/python3.10/site-packages (from boto3) (1.35.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.29->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.29->boto3) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.29->boto3) (1.16.0)\n",
      "Downloading boto3-1.35.29-py3-none-any.whl (139 kB)\n",
      "Installing collected packages: boto3\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.35.17\n",
      "    Uninstalling boto3-1.35.17:\n",
      "      Successfully uninstalled boto3-1.35.17\n",
      "Successfully installed boto3-1.35.29\n",
      "Requirement already satisfied: botocore in /home/ec2-user/.local/lib/python3.10/site-packages (1.35.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting numpy>=1.19.5 (from scikit-learn)\n",
      "  Downloading numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mkl-fft 1.3.10 requires mkl, which is not installed.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n",
      "sagemaker 2.231.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.1.1 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.1.1 scikit-learn-1.5.2\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.231.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.232.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.34.142 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.35.29)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.23.0)\n",
      "Collecting numpy<2.0,>=1.9.0 (from sagemaker)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.2.2)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.25.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.4)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.29 in /home/ec2-user/.local/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.35.29)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.19.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.1.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.9.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (13.7.1)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.232.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, sagemaker\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.231.0\n",
      "    Uninstalling sagemaker-2.231.0:\n",
      "      Successfully uninstalled sagemaker-2.231.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mkl-fft 1.3.10 requires mkl, which is not installed.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 sagemaker-2.232.1\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.8.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.9.1\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Install/Upgrade dependencies\n",
    "!pip install --upgrade awscli --user\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade boto3\n",
    "!pip install --upgrade botocore\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade sagemaker\n",
    "!pip install --upgrade nltk\n",
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Before you proceed with this lab for the first time, we recommend that you restart the kernel by choosing __Kernel__ > __Restart Kernel__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages that are used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import os, io, struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell includes a few helper functions that  plot a confusion matrix and calculate other key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "    \n",
    "def print_metrics(test_labels, target_predicted_binary):\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    Sensitivity  = float(TP)/(TP+FN)*100\n",
    "    # Specificity or true negative rate\n",
    "    Specificity  = float(TN)/(TN+FP)*100\n",
    "    # Precision or positive predictive value\n",
    "    Precision = float(TP)/(TP+FP)*100\n",
    "    # Negative predictive value\n",
    "    NPV = float(TN)/(TN+FN)*100\n",
    "    # Fall out or false positive rate\n",
    "    FPR = float(FP)/(FP+TN)*100\n",
    "    # False negative rate\n",
    "    FNR = float(FN)/(TP+FN)*100\n",
    "    # False discovery rate\n",
    "    FDR = float(FP)/(TP+FP)*100\n",
    "    # Overall accuracy\n",
    "    ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "\n",
    "    print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "    print(f\"Specificity or TNR: {Specificity}%\") \n",
    "    print(f\"Precision: {Precision}%\")   \n",
    "    print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "    print( f\"False Positive Rate: {FPR}%\") \n",
    "    print(f\"False Negative Rate: {FNR}%\")  \n",
    "    print(f\"False Discovery Rate: {FDR}%\" )\n",
    "    print(f\"Accuracy: {ACC}%\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading the dataset\n",
    "\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will load the dataset. The dataset has already been downloaded by Amazon Sagemaker Studio. Use the __pandas__ library to read the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Loading the training data:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/imdb.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performing exploratory data analysis\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will examine the dataset. \n",
    "\n",
    "Complete the following functions. The first one has been provided so that you can learn the format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Listing the first eight rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eight_rows(df):\n",
    "    # Implement this function\n",
    "    return df.head(8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  What I hoped for (or even expected) was the we...      0\n",
      "1  Garden State must rate amongst the most contri...      0\n",
      "2  There is a lot wrong with this film. I will no...      1\n",
      "3  To qualify my use of \"realistic\" in the summar...      1\n",
      "4  Dirty War is absolutely one of the best politi...      1\n",
      "5  Many other viewers are saying that this is not...      1\n",
      "6  I understand that Roger Corman loves to do thi...      0\n",
      "7  I love this show. I watched every episode last...      0\n"
     ]
    }
   ],
   "source": [
    "print(show_eight_rows(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: What is the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_shape(df):\n",
    "    # Implement this function\n",
    "    ### BEGIN_SOLUTION\n",
    "    return df.shape\n",
    "    ### END_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(show_data_shape(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: How many positive and negative instances are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_instances(df):\n",
    "    # Implement this function\n",
    "    ### BEGIN_SOLUTION\n",
    "    return df['label'].value_counts()\n",
    "    ### END_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(show_data_instances(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Does the data have any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_values(df):\n",
    "    # Implement this function\n",
    "    ### BEGIN_SOLUTION\n",
    "    return df.isna().sum()\n",
    "    ### END_SOLUTION\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(show_missing_values(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the first pass: Minimal processing\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will perform the minimum steps that are needed to train a classification model. You will use this trained model to see the impact of processing text on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the Natural Langauge ToolKit (NLTK) package and the Regular Expression (re) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Splitting the data into datasets for training, validation, and testing\n",
    "\n",
    "In this task, you will split the dataset so that you have 80 percent of the dataset for training, and 10 percent each for validation and testing.\n",
    "\n",
    "To split the dataset, use the `train_test_split` function from __scikit-learn__. For more information about this function, see the [scikit-learn test_train_split documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) at https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html.\n",
    "\n",
    "Specify __df__ as the dataset. Split this dataset into a __train__ set and a __test_and_validate__ set. Then, split the __train_and_validate__ set into the __test__ set and the __validate__ set.\n",
    "\n",
    "(*Optional*) For repeatable results, shuffle the deck and **random_state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# uncomment the following lines and implement your solution\n",
    "def split_data(df):\n",
    "    # train, test_and_validate = train_test_split(....)\n",
    "    # test, validate = train_test_split(....)\n",
    "    ### BEGIN_SOLUTION\n",
    "    train, test_and_validate = train_test_split(df,\n",
    "                                            test_size=0.2,\n",
    "                                            shuffle=True,\n",
    "                                            random_state=324\n",
    "                                            )\n",
    "    test, validate = train_test_split(test_and_validate,\n",
    "                                                test_size=0.5,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=324)\n",
    "    ### END_SOLUTION\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether your datasets are split correctly by running the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "(5000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = split_data(df)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the processing pipeline\n",
    "\n",
    "In this cell, the basic processing pipeline is assembled for the text data. You will now modify this implementation to add more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (40000, 2) (5000, 2) (5000, 2)\n",
      "Datasets shapes after processing:  (40000, 500) (5000, 500) (5000, 500)\n",
      "CPU times: user 7.48 s, sys: 95.2 ms, total: 7.58 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "text_features = ['text']\n",
    "model_target = 'label'\n",
    "\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(max_features=500))\n",
    "])\n",
    "\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('text_pre_0', text_processor_0, text_features[0])\n",
    "])\n",
    "\n",
    "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n",
    "train_matrix = data_preprocessor.fit_transform(train)\n",
    "test_matrix = data_preprocessor.transform(test)\n",
    "validate_matrix = data_preprocessor.transform(validate)\n",
    "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, the data must be uploaded to Amazon Simple Storage Service (Amazon S3) in the correct format. XGBoost uses a comma-separated values (CSV) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, X_train, y_train, is_test=False):\n",
    "    csv_buffer = io.StringIO()\n",
    "    features = [t.toarray().astype('float32').flatten().tolist() for t in X_train]\n",
    "    if is_test:\n",
    "        temp_list = features\n",
    "    else:\n",
    "        temp_list = np.insert(features, 0, y_train['label'], axis=1)\n",
    "    np.savetxt(csv_buffer, temp_list, delimiter=',' )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'c127808a3228842l7775723t1w505704594257-labbucket-eutc1xxyq9qx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the file names for this pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='lab41'\n",
    "train_file='train-pass1.csv'\n",
    "validate_file='validate-pass1.csv'\n",
    "test_file='test-pass1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the train, validate, and test datasets to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_s3_csv(train_file, 'train', train_matrix, train)\n",
    "upload_s3_csv(validate_file, 'validate', validate_matrix, validate)\n",
    "upload_s3_csv(test_file, 'test', test_matrix, test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Training an XGBoost model\n",
    "\n",
    "Uncomment and complete the following SageMaker function to create an `Estimator`. Use the following parameters:\n",
    "- **role**: Use the current SageMaker role (__Hint:__ Use `sagemaker.get_execution_role()`)\n",
    "- **instance count**: `1`\n",
    "- **instance type**: `ml.m5.xlarge`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "s3_output_location=f's3://{bucket}/{prefix}/output/'\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"error\",\n",
    "             \"objective\": \"binary:logistic\",\n",
    "             \"silent\" : 1}\n",
    "\n",
    "# xgb_model=sagemaker.estimator.Estimator(container,\n",
    "#                                         role=<INSERT_ROLE_HERE>,\n",
    "#                                         instance_count=<INSERT_COUNT_HERE>,\n",
    "#                                         instance_type=<INSERT_INSTANCE_TYPE_HERE>,\n",
    "#                                         output_path=s3_output_location,\n",
    "#                                         hyperparameters=hyperparams,\n",
    "#                                         sagemaker_session=sagemaker.Session())\n",
    "### BEGIN_SOLUTION\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                        role=sagemaker.get_execution_role(),\n",
    "                                        instance_count=1,\n",
    "                                        instance_type='ml.m5.2xlarge',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the two data channels. One data channel is for the training data that's used to train the model. The second data channel is for the validation data that's used to generate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/train/{train_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/validate/{validate_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. (This step might take a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgb-pass1-09-29-2024-23-45-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-29 23:45:10 Starting - Starting the training job...\n",
      "2024-09-29 23:45:31 Starting - Preparing the instances for training....\n",
      "2024-09-29 23:45:57 Downloading - Downloading input data...\n",
      "2024-09-29 23:46:17 Downloading - Downloading the training image.....\n",
      "2024-09-29 23:46:48 Training - Training image download completed. Training in progress......\n",
      "2024-09-29 23:47:19 Uploading - Uploading generated training model..\n",
      "2024-09-29 23:47:32 Completed - Training job completed\n",
      "CPU times: user 124 ms, sys: 10.5 ms, total: 135 ms\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False, job_name='xgb-pass1-'+datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the metrics from the current XGBoost job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:error</td>\n",
       "      <td>0.16255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:error</td>\n",
       "      <td>0.19780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp       metric_name    value\n",
       "0        0.0       train:error  0.16255\n",
       "1        0.0  validation:error  0.19780"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n",
    "                                         metric_names = ['train:error','validation:error']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial results don't seem to be useful. Use the __test__ dataset to calculate more metrics. (This step might take a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-09-29-23-48-01-145\n",
      "INFO:sagemaker:Creating transform job with name: xgboost-pass1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34m[2024-09-29:23:52:38:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:38:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:38:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:38:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:38:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:38:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [27] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [27] [INFO] Listening at: unix:/tmp/gunicorn.sock (27)\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [27] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [48] [INFO] Booting worker with pid: 48\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [49] [INFO] Booting worker with pid: 49\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:38 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[34m[2024-09-29 23:52:39 +0000] [73] [INFO] Booting worker with pid: 73\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [27] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [27] [INFO] Listening at: unix:/tmp/gunicorn.sock (27)\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [27] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [48] [INFO] Booting worker with pid: 48\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [49] [INFO] Booting worker with pid: 49\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:38 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[35m[2024-09-29 23:52:39 +0000] [73] [INFO] Booting worker with pid: 73\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:43 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:43 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:43 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:43 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:44:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9747 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9704 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9729 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9705 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9732 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9739 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9730 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9168 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:44:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9747 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9704 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9729 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-09-29:23:52:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9705 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9732 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9739 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9730 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Sep/2024:23:52:44 +0000] \"POST /invocations HTTP/1.1\" 200 9168 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-09-29T23:52:43.087:[sagemaker logs]: MaxConcurrentTransforms=8, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "!\n",
      "CPU times: user 1.98 s, sys: 95.1 ms, total: 2.08 s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "upload_s3_csv('batch-in.csv', 'batch-in', test_matrix, test, True)\n",
    "batch_X_file='batch-in.csv'\n",
    "batch_output = f's3://{bucket}/{prefix}/batch-out/'\n",
    "batch_input = f's3://{bucket}/{prefix}/batch-in/{batch_X_file}'\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line',\n",
    "                         job_name='xgboost-pass1')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/batch-out/batch-in.csv.out')\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity or TPR: 85.4672704816797%\n",
      "Specificity or TNR: 79.15208090237262%\n",
      "Precision: 79.47932618683001%\n",
      "Negative Predictive Value: 85.2177554438861%\n",
      "False Positive Rate: 20.847919097627383%\n",
      "False Negative Rate: 14.532729518320298%\n",
      "False Discovery Rate: 20.520673813169985%\n",
      "Accuracy: 82.22%\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Second pass: Normalizing the text\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will perform some standard preprocessing tasks on the text before you retrain the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Removing stopwords that might impact sentiment\n",
    "\n",
    "You could remove all the stopwords, but you might want to keep the stopwords that could impact the sentiment, such as __not__ or __don't__. \n",
    "\n",
    "A few stopwords to exclude have been provided. Update the function to remove other words that might impact sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of stopwords from the NLTK library\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(stopwords):\n",
    "    # Implement this function\n",
    "    excluding = ['against', 'not', 'don', 'don\\'t','ain', 'are', 'aren\\'t']\n",
    "    ### BEGIN_SOLUTION\n",
    "    excluding = ['against', 'not', 'don', 'don\\'t','ain', 'are', 'aren\\'t', 'could', 'couldn\\'t',\n",
    "             'did', 'didn\\'t', 'does', 'doesn\\'t', 'had', 'hadn\\'t', 'has', 'hasn\\'t', \n",
    "             'have', 'haven\\'t', 'is', 'isn\\'t', 'might', 'mightn\\'t', 'must', 'mustn\\'t',\n",
    "             'need', 'needn\\'t','should', 'shouldn\\'t', 'was', 'wasn\\'t', 'were', \n",
    "             'weren\\'t', 'won\\'t', 'would', 'wouldn\\'t']\n",
    "    ### END_SOLUTION\n",
    "    return [word for word in stop if word not in excluding]\n",
    "\n",
    "# New stopword list\n",
    "stopwords = remove_stopwords(stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Adding cleanup steps\n",
    "\n",
    "Update the following `clean` function to complete the following tasks:\n",
    "- Remove leading spaces and trailing spaces\n",
    "- Remove any HTML tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = SnowballStemmer('english')\n",
    "def clean(sent):\n",
    "    # Implement this function\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('\\s+', ' ', sent)\n",
    "    ### BEGIN_SOLUTION\n",
    "    sent = sent.strip()\n",
    "    sent = re.compile('<.*?>').sub('',sent)\n",
    "    ### END_SOLUTION\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokenize(sent):\n",
    "        # You are applying custom filtering here. Feel free to try different things.\n",
    "        # Check if it is not numeric, its length > 2, and it is not in stopwords\n",
    "        if(not w.isnumeric()) and (len(w)>2) and (w not in stopwords):  \n",
    "            # Stem and add to filtered list\n",
    "            filtered_sentence.append(snow.stem(w))\n",
    "    final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new test, validate, and test dataframes by using the function that you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "(5000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the next line and implement the function call to split_data\n",
    "#train, validate, test = \n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "train, validate, test = split_data(df)\n",
    "### END_SOLUTION\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has been updated to include a call to the previously defined `clean` function from the `CountVectorizer`. This function will take a little longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (40000, 2) (5000, 2) (5000, 2)\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ec2-user/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/share/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:976\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m--> 976\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    875\u001b[0m             delayed(func)(\n\u001b[1;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    882\u001b[0m             )\n\u001b[1;32m    883\u001b[0m         )\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1314\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:541\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    539\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    546\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:108\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mclean\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m### END_SOLUTION\u001b[39;00m\n\u001b[1;32m     10\u001b[0m filtered_sentence \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# You are applying custom filtering here. Feel free to try different things.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Check if it is not numeric, its length > 2, and it is not in stopwords\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m w\u001b[38;5;241m.\u001b[39misnumeric()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords):  \n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Stem and add to filtered list\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         filtered_sentence\u001b[38;5;241m.\u001b[39mappend(snow\u001b[38;5;241m.\u001b[39mstem(w))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ec2-user/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/share/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "text_features = ['text']\n",
    "model_target = 'label'\n",
    "\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(preprocessor=clean, max_features=500))\n",
    "])\n",
    "\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('text_pre_0', text_processor_0, text_features[0])\n",
    "])\n",
    "\n",
    "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n",
    "train_matrix = data_preprocessor.fit_transform(train)\n",
    "test_matrix = data_preprocessor.transform(test)\n",
    "validate_matrix = data_preprocessor.transform(validate)\n",
    "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the file names for this pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='lab41'\n",
    "train_file='train_pass2.csv'\n",
    "validate_file='validate_pass2.csv'\n",
    "test_file='test_pass2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Uploading the files to Amazon S3\n",
    "\n",
    "Use the previous code to upload the new files to Amazon S3. \n",
    "\n",
    "__Tip:__ Copy the code and paste it into the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN_SOLUTION\n",
    "upload_s3_csv(train_file, 'train', train_matrix, train)\n",
    "upload_s3_csv(validate_file, 'validate', validate_matrix, validate)\n",
    "upload_s3_csv(test_file, 'test', test_matrix, test, True)\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Creating the estimator and setting up the data channels\n",
    "\n",
    "Use the previous code to set up the estimator and data channels. \n",
    "\n",
    "__Tip:__ Copy the code from the previous cell and paste it into the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker:Creating training-job with name: xgb-pass2-09-29-2024-23-58-40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-29 23:58:41 Starting - Starting the training job.\n",
      "2024-09-29 23:58:55 Starting - Preparing the instances for training.....\n",
      "2024-09-29 23:59:23 Downloading - Downloading input data...\n",
      "2024-09-29 23:59:43 Downloading - Downloading the training image.....\n",
      "2024-09-30 00:00:14 Training - Training image download completed. Training in progress......\n",
      "2024-09-30 00:00:44 Uploading - Uploading generated training model..\n",
      "2024-09-30 00:00:58 Completed - Training job completed\n",
      "CPU times: user 207 ms, sys: 4.26 ms, total: 212 ms\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"error\",\n",
    "             \"objective\": \"binary:logistic\",\n",
    "             \"silent\" : 1}\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                        sagemaker.get_execution_role(),\n",
    "                                        instance_count=1,\n",
    "                                        instance_type='ml.m5.2xlarge',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        hyperparameters = hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/train/{train_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/validate/{validate_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "### END_SOLUTION\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False, job_name='xgb-pass2-'+datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:error</td>\n",
       "      <td>0.14404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:error</td>\n",
       "      <td>0.18630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp       metric_name    value\n",
       "0        0.0       train:error  0.14404\n",
       "1        0.0  validation:error  0.18630"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n",
    "                                         metric_names = ['train:error','validation:error']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Creating a batch transformer job\n",
    "\n",
    "Using the previous code, create a transformer job. (This step might take a few minutes to complete.) \n",
    "\n",
    "__Tip:__ Copy the code from the previous example and paste it into the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# upload_s3_csv('batch-in.csv', 'batch-in', test_matrix, test, True)\n",
    "# batch_X_file='batch-in.csv'\n",
    "# batch_output = f's3://{bucket}/{prefix}/batch-out/'\n",
    "# batch_input = f's3://{bucket}/{prefix}/batch-in/{batch_X_file}'\n",
    "\n",
    "# xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "#                                        instance_type='ml.m5.2xlarge',\n",
    "#                                        strategy='MultiRecord',\n",
    "#                                        assemble_with='Line',\n",
    "#                                        output_path=batch_output)\n",
    "\n",
    "# xgb_transformer.transform(data=batch_input,\n",
    "#                          data_type='S3Prefix',\n",
    "#                          content_type='text/csv',\n",
    "#                          split_type='Line',\n",
    "#                          job_name='xgboost-pass1')\n",
    "# xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-09-30-00-01-19-863\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-09-30-00-01-20-518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................\u001b[34m[2024-09-30:00:07:01:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:01:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:01:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [27] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [27] [INFO] Listening at: unix:/tmp/gunicorn.sock (27)\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [27] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:01 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:02 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:02 +0000] [56] [INFO] Booting worker with pid: 56\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:02 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:02 +0000] [58] [INFO] Booting worker with pid: 58\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:07:02 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:06:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:06 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:06 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9711 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9704 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9747 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9729 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-09-30:00:07:07:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9705 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9739 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9732 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9168 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [30/Sep/2024:00:07:07 +0000] \"POST /invocations HTTP/1.1\" 200 9730 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-09-30T00:07:06.608:[sagemaker logs]: MaxConcurrentTransforms=8, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "!\n",
      "CPU times: user 666 ms, sys: 27.7 ms, total: 693 ms\n",
      "Wall time: 6min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "### END_SOLUTION\n",
    "\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity or TPR: 85.4672704816797%\n",
      "Specificity or TNR: 79.15208090237262%\n",
      "Precision: 79.47932618683001%\n",
      "Negative Predictive Value: 85.2177554438861%\n",
      "False Positive Rate: 20.847919097627383%\n",
      "False Negative Rate: 14.532729518320298%\n",
      "False Discovery Rate: 20.520673813169985%\n",
      "Accuracy: 82.22%\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the new model better or worse than the first model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tuning hyperparameters\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will create a hyperparameter tuning job to tune the model.\n",
    "\n",
    "__Note__: Tuning Hyperparameters takes about an hour to complete. If you don't have enough time, proceed to Section 7. You can also skip to section 7 after you start the tuning job, and return to its results later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Creating the estimator to tune\n",
    "\n",
    "The first step is to create an estimator to tune. Uncomment and complete the following estimator code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = sagemaker.estimator.Estimator(....)\n",
    "### BEGIN_SOLUTION\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker.get_execution_role(), \n",
    "                                    instance_count= 1, # make sure you have limit set for these instances\n",
    "                                    instance_type='ml.m5.2xlarge', \n",
    "                                    output_path=f's3://{bucket}/{prefix}/output',\n",
    "                                    sagemaker_session=sagemaker.Session())\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(eval_metric='error',\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=42,\n",
    "                        silent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Creating the hyperparameter ranges\n",
    "\n",
    "Using the [XGBoost Tuning documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html), add hyperparameter ranges to the following cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# hyperparameter_ranges = {'alpha': ContinuousParameter(0,1000)}\n",
    "\n",
    "# ### BEGIN_SOLUTION\n",
    "# hyperparameter_ranges = {'alpha': ContinuousParameter(0, 1000),\n",
    "#                          'min_child_weight': ContinuousParameter(0, 120),\n",
    "#                          'subsample': ContinuousParameter(0.5, 1),\n",
    "#                          'eta': ContinuousParameter(0.1, 0.5),  \n",
    "#                          'num_round': IntegerParameter(1,4000)\n",
    "#                          }\n",
    "# ### END_SOLUTION\n",
    "# hyperparameter_ranges = {\n",
    "#     'batch_size': IntegerParameter(32, 512),\n",
    "#     'negative_samples': IntegerParameter(5, 20),\n",
    "#     'window_size': IntegerParameter(3, 10),\n",
    "#     'vector_dim': IntegerParameter(100, 300),\n",
    "#     'learning_rate': ContinuousParameter(0.01, 0.1),\n",
    "#     'epochs': IntegerParameter(5, 50)\n",
    "# }\n",
    "### BEGIN_SOLUTION\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 1000),\n",
    "    'min_child_weight': ContinuousParameter(0, 120),\n",
    "    'subsample': ContinuousParameter(0.5, 1),\n",
    "    'eta': ContinuousParameter(0.1, 0.5),  \n",
    "    'num_round': IntegerParameter(1, 4000)\n",
    "}\n",
    "### END_SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Specifying the target metrics\n",
    "\n",
    "Update the `objective_metric_name` and `objective_type` to appropriate values for a binary classification problem. For more information, see the [XGBoost Tuning documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_metric_name = '<INSERT_VALUE_HERE>'\n",
    "# objective_type = '<INSERT_VALUE_HERE>'\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "objective_metric_name = 'validation:error'\n",
    "objective_type = 'Minimize'\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = HyperparameterTuner(xgb,\n",
    "#                             objective_metric_name,\n",
    "#                             hyperparameter_ranges,\n",
    "#                             max_jobs=10, # Set this to 10 or above depending upon budget & available time.\n",
    "#                             max_parallel_jobs=1,\n",
    "#                             objective_type=objective_type,\n",
    "#                             early_stopping_type='Auto',\n",
    "#                            )\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,  # Adjust based on resources\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type='Auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the tuning job. Note that this job might take around 60 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: blazingtext-240930-0049\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateHyperParameterTuningJob operation: The hyperparameter tuning job that you requested has the following untunable hyperparameters: [eta, alpha, num_round, subsample, min_child_weight]. For the algorithm, 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1, you can tune only [batch_size, negative_samples, buckets, min_count, min_char, window_size, mode, vector_dim, subwords, word_ngrams, sampling_threshold, max_char, learning_rate, epochs]. Delete untunable hyperparameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/tuner.py:1039\u001b[0m, in \u001b[0;36mHyperparameterTuner.fit\u001b[0;34m(self, inputs, job_name, include_cls_metadata, estimator_kwargs, wait, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start a hyperparameter tuning job.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m        arguments are needed.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1039\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_with_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_cls_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/tuner.py:1050\u001b[0m, in \u001b[0;36mHyperparameterTuner._fit_with_estimator\u001b[0;34m(self, inputs, job_name, include_cls_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_estimator_for_tuning(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, inputs, job_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_tuning(job_name\u001b[38;5;241m=\u001b[39mjob_name, include_cls_metadata\u001b[38;5;241m=\u001b[39minclude_cls_metadata)\n\u001b[0;32m-> 1050\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_tuning_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TuningJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/tuner.py:2149\u001b[0m, in \u001b[0;36m_TuningJob.start_new\u001b[0;34m(cls, tuner, inputs)\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Amazon SageMaker HyperParameter Tuning job.\u001b[39;00m\n\u001b[1;32m   2133\u001b[0m \n\u001b[1;32m   2134\u001b[0m \u001b[38;5;124;03mThe new HyperParameter Tuning job uses the provided `tuner` and `inputs`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;124;03m    information about the started job.\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2147\u001b[0m tuner_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_args(tuner, inputs)\n\u001b[0;32m-> 2149\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtuner_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(tuner\u001b[38;5;241m.\u001b[39msagemaker_session, tuner\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3318\u001b[0m, in \u001b[0;36mSession.create_tuning_job\u001b[0;34m(self, job_name, tuning_config, training_config, training_config_list, warm_start_config, tags, autotune)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtune request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   3316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_hyper_parameter_tuning_job(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest)\n\u001b[0;32m-> 3318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6606\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6591\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6594\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6595\u001b[0m ):\n\u001b[1;32m   6596\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6597\u001b[0m \n\u001b[1;32m   6598\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6604\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:3316\u001b[0m, in \u001b[0;36mSession.create_tuning_job.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   3314\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating hyperparameter tuning job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m   3315\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtune request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m-> 3316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_hyper_parameter_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateHyperParameterTuningJob operation: The hyperparameter tuning job that you requested has the following untunable hyperparameters: [eta, alpha, num_round, subsample, min_child_weight]. For the algorithm, 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1, you can tune only [batch_size, negative_samples, buckets, min_count, min_char, window_size, mode, vector_dim, subwords, word_ngrams, sampling_threshold, max_char, learning_rate, epochs]. Delete untunable hyperparameters."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuner.fit(inputs=data_channels, include_cls_metadata=False, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try Section 7 while you wait, don't run the next cell and go to Section 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tuning job available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/tuner.py:1389\u001b[0m, in \u001b[0;36mHyperparameterTuner.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wait for latest hyperparameter tuning job to finish.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_last_tuning_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_tuning_job\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/tuner.py:1466\u001b[0m, in \u001b[0;36mHyperparameterTuner._ensure_last_tuning_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Placeholder docstring\"\"\"\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_tuning_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tuning job available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No tuning job available"
     ]
    }
   ],
   "source": [
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the tuning job is complete, you can view the metrics from the tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HyperparameterTuningJobAnalytics\n\u001b[0;32m----> 4\u001b[0m tuner_analytics \u001b[38;5;241m=\u001b[39m HyperparameterTuningJobAnalytics(\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m, sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker\u001b[38;5;241m.\u001b[39mSession())\n\u001b[1;32m      6\u001b[0m df_tuning_job_analytics \u001b[38;5;241m=\u001b[39m tuner_analytics\u001b[38;5;241m.\u001b[39mdataframe()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Sort the tuning job analytics by the final metrics value\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the best hyperparameter job\n",
    "\n",
    "After the tuning job is complete, you can find the best tuning job from the **HyperparameterTuner** object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attached_tuner \u001b[38;5;241m=\u001b[39m HyperparameterTuner\u001b[38;5;241m.\u001b[39mattach(\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_tuning_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m, sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker\u001b[38;5;241m.\u001b[39mSession())\n\u001b[1;32m      2\u001b[0m best_training_job \u001b[38;5;241m=\u001b[39m attached_tuner\u001b[38;5;241m.\u001b[39mbest_training_job()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "best_training_job = attached_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_training_job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Estimator\n\u001b[0;32m----> 2\u001b[0m algo_estimator \u001b[38;5;241m=\u001b[39m Estimator\u001b[38;5;241m.\u001b[39mattach(\u001b[43mbest_training_job\u001b[49m)\n\u001b[1;32m      4\u001b[0m best_algo_model \u001b[38;5;241m=\u001b[39m algo_estimator\u001b[38;5;241m.\u001b[39mcreate_model(env\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/csv\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_training_job' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test data through the data processing pipeline so that you can test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (40000, 2) (5000, 2) (5000, 2)\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ec2-user/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/share/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:976\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m--> 976\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    875\u001b[0m             delayed(func)(\n\u001b[1;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    882\u001b[0m             )\n\u001b[1;32m    883\u001b[0m         )\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1314\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/pipeline.py:541\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    539\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    546\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:108\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mclean\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m### END_SOLUTION\u001b[39;00m\n\u001b[1;32m     10\u001b[0m filtered_sentence \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# You are applying custom filtering here. Feel free to try different things.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Check if it is not numeric, its length > 2, and it is not in stopwords\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m w\u001b[38;5;241m.\u001b[39misnumeric()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords):  \n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Stem and add to filtered list\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         filtered_sentence\u001b[38;5;241m.\u001b[39mappend(snow\u001b[38;5;241m.\u001b[39mstem(w))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/home/ec2-user/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/share/nltk_data'\n    - '/home/ec2-user/anaconda3/envs/python3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "text_features = ['text']\n",
    "model_target = 'label'\n",
    "\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(preprocessor=clean, max_features=500))\n",
    "])\n",
    "\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('text_pre_0', text_processor_0, text_features[0])\n",
    "])\n",
    "\n",
    "print('Datasets shapes before processing: ', train.shape, validate.shape, test.shape)\n",
    "train_matrix = data_preprocessor.fit_transform(train)\n",
    "test_matrix = data_preprocessor.transform(test)\n",
    "validate_matrix = data_preprocessor.transform(validate)\n",
    "print('Datasets shapes after processing: ', train_matrix.shape, validate_matrix.shape, test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the test data on a batch transformation by using the best algorithm from the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "upload_s3_csv('batch-in.csv', 'batch-in', test_matrix, test, True)\n",
    "\n",
    "batch_output = f's3://{bucket}/{prefix}/batch-out/'\n",
    "batch_input = f's3://{bucket}/{prefix}/batch-in/{batch_X_file}'\n",
    "\n",
    "xgb_transformer = best_algo_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the results to calculate the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/batch-out/batch-in.csv.out')\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),sep=',',names=['class'])\n",
    "\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix and print the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using BlazingText\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will use BlazingText, which is a built-in Amazon SageMaker algorithm. BlazingText can perform classification without modifications. You will reformat the data for BlazingText. You will then use the data to train the algorithm and compare the results to the previous models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by obtaining the container for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "WARNING:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "container = retrieve('blazingtext',boto3.Session().region_name,\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the prefixes for the training, validation, and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "    \n",
    "prefix='lab41'\n",
    "train_file='blazing_train.txt'\n",
    "validate_file='blazing_validate.txt'\n",
    "test_file='blazing_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind yourself of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29572</th>\n",
       "      <td>Caught this movie on the tube on a Sunday. I t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42816</th>\n",
       "      <td>Seeing as Keifer Sutherland plays my favorite ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>Stan as a bullfighter, and a good one, is quit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38282</th>\n",
       "      <td>Ok so I was bored and I watched it all the way...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36321</th>\n",
       "      <td>This can't be Mandy Schaffer's last film. Some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "29572  Caught this movie on the tube on a Sunday. I t...      0\n",
       "42816  Seeing as Keifer Sutherland plays my favorite ...      1\n",
       "15853  Stan as a bullfighter, and a good one, is quit...      1\n",
       "38282  Ok so I was bored and I watched it all the way...      0\n",
       "36321  This can't be Mandy Schaffer's last film. Some...      0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "BlazingText needs the data in the following format:\n",
    "\n",
    "\\__label__1 Caught this movie on the tube on a Sunday...\n",
    "\n",
    "The following two cells convert the dataframes into the correct format, and upload them to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'TQ57AJYHDAE0KWMW',\n",
       "  'HostId': 'lvKuB1TO6jgEfzNgHqkdlGROW8IDfExwH5RdcSd2pHLqbpEbZYvqL8x7NWbhq3NPFohcw7UjO/F+0eZ3UyMB4C85Ad3wtj0zhuzCCeDjymg=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'lvKuB1TO6jgEfzNgHqkdlGROW8IDfExwH5RdcSd2pHLqbpEbZYvqL8x7NWbhq3NPFohcw7UjO/F+0eZ3UyMB4C85Ad3wtj0zhuzCCeDjymg=',\n",
       "   'x-amz-request-id': 'TQ57AJYHDAE0KWMW',\n",
       "   'date': 'Mon, 30 Sep 2024 00:13:24 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"d2cbe833d8eace19960f9eeb3939980a\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d2cbe833d8eace19960f9eeb3939980a\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blazing_text_buffer = io.StringIO()\n",
    "train.to_string(buf=blazing_text_buffer, columns=['label','text'], header=False, index=False, formatters=\n",
    "                         {'label': '__label__{}'.format})\n",
    "s3r = boto3.resource('s3')\n",
    "s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', train_file)).put(Body=blazing_text_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'SFPYZCG7FG909FXZ',\n",
       "  'HostId': 'Kt7YkycfTqpVVR84Vp3nlgywu+PeuCyv+HCPLUg10VunX6CDFxpztHgxBE0SMmnG3nEvjMp3tuI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Kt7YkycfTqpVVR84Vp3nlgywu+PeuCyv+HCPLUg10VunX6CDFxpztHgxBE0SMmnG3nEvjMp3tuI=',\n",
       "   'x-amz-request-id': 'SFPYZCG7FG909FXZ',\n",
       "   'date': 'Mon, 30 Sep 2024 00:13:33 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"454e6e28ce395eb3c0ec56e8a5755f20\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"454e6e28ce395eb3c0ec56e8a5755f20\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blazing_text_buffer = io.StringIO()\n",
    "validate.to_string(buf=blazing_text_buffer, columns=['label','text'], header=False, index=False, formatters=\n",
    "                         {'label': '__label__{}'.format})\n",
    "s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', validate_file)).put(Body=blazing_text_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Training the BlazingText estimator\n",
    "\n",
    "In the next cell, uncomment and complete the estimator code by specifying the missing values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bt_model = sagemaker.estimator.Estimator(container,\n",
    "#                                         sagemaker.get_execution_role(), \n",
    "#                                         instance_count=, \n",
    "#                                         instance_type=,\n",
    "#                                         volume_size = 30,\n",
    "#                                         max_run = 360000,\n",
    "#                                         input_mode= 'File',\n",
    "#                                         output_path=,\n",
    "#                                         sagemaker_session=\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         sagemaker.get_execution_role(), \n",
    "                                         instance_count=1, \n",
    "                                         instance_type='ml.c4.4xlarge',\n",
    "                                         volume_size = 30,\n",
    "                                         max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session())\n",
    "\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            min_count=2,\n",
    "                            learning_rate=0.05,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the training channel and the validate channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/blazing/{train_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    f's3://{bucket}/{prefix}/blazing/{validate_file}',\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels_3 = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Starting the training job\n",
    "\n",
    "Start the training job by entering the following code. (This step might take a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: blazingtext-2024-09-30-00-14-35-672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-30 00:14:36 Starting - Starting the training job.\n",
      "2024-09-30 00:14:50 Starting - Preparing the instances for training.......\n",
      "2024-09-30 00:15:27 Downloading - Downloading input data...\n",
      "2024-09-30 00:15:47 Downloading - Downloading the training image...\n",
      "2024-09-30 00:16:08 Training - Training image download completed. Training in progress.......\n",
      "2024-09-30 00:16:44 Uploading - Uploading generated training model.\n",
      "2024-09-30 00:16:56 Completed - Training job completed\n",
      "CPU times: user 123 ms, sys: 1.15 ms, total: 124 ms\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "bt_model.fit(inputs=data_channels_3, logs=False)\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training job is complete, view the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:accuracy</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:accuracy</td>\n",
       "      <td>0.8722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp          metric_name   value\n",
       "0        0.0       train:accuracy  0.9142\n",
       "1        0.0  validation:accuracy  0.8722"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.analytics.TrainingJobAnalytics(bt_model._current_job_name, \n",
    "                                         metric_names = ['train:accuracy','validation:accuracy']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the test data so that it can be formatted to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16591</th>\n",
       "      <td>This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21931</th>\n",
       "      <td>I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22143</th>\n",
       "      <td>There have been several comments already on the site focusing on the \"prestige\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \"Evita\" at that year's Oscars began \"Well, thank God that \"The English Patient\" had no songs in it.\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \"Howard's End\" proved that one of the hardest things that an actor can do is make the portrayal of \"goodness\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \"old bookseller.\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \"Dennis Hoey\" by kidnapping Tobel. The only clue left by Tobel is a list of \"dancing men.\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "16591                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.   \n",
       "21931                                                                                                                                                                                                                                                             I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.   \n",
       "22143  There have been several comments already on the site focusing on the \"prestige\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \"Evita\" at that year's Oscars began \"Well, thank God that \"The English Patient\" had no songs in it.\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \"Howard's End\" proved that one of the hardest things that an actor can do is make the portrayal of \"goodness\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.   \n",
       "1133                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!   \n",
       "10413                                                                                                                                                                                                                                              Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \"old bookseller.\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \"Dennis Hoey\" by kidnapping Tobel. The only clue left by Tobel is a list of \"dancing men.\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.   \n",
       "\n",
       "       label  \n",
       "16591      1  \n",
       "21931      0  \n",
       "22143      1  \n",
       "1133       1  \n",
       "10413      1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_test = test.copy()\n",
    "bt_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the dataset into the format that BlazingText needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bt_test['text'].str.strip()\n",
    "bt_test.replace(r'\\\\n','', regex=True, inplace = True)\n",
    "bt_test.rename(columns={'text':'source'}, inplace=True)\n",
    "bt_test.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"source\":\"This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.\"}\n",
      "{\"source\":\"I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.\"}\n",
      "{\"source\":\"There have been several comments already on the site focusing on the \\\"prestige\\\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \\\"Evita\\\" at that year's Oscars began \\\"Well, thank God that \\\"The English Patient\\\" had no songs in it.\\\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \\\"Howard's End\\\" proved that one of the hardest things that an actor can do is make the portrayal of \\\"goodness\\\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.\"}\n",
      "{\"source\":\"My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!\"}\n",
      "{\"source\":\"Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \\\"old bookseller.\\\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \\\"Dennis Hoey\\\" by kidnapping Tobel. The only clue left by Tobel is a list of \\\"dancing men.\\\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bt_test.head().to_json(orient=\"records\", lines=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_file = 'bt_input.json'\n",
    "blazing_text_buffer = io.StringIO()\n",
    "bt_test.to_json(path_or_buf=blazing_text_buffer, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'EY66BVF6REZRFJ0Z',\n",
       "  'HostId': 'FcHPar6J3WYgOeP25nhIL8qCv4eno6UmGSovgBEeQAECzO0nmit4aYUwMMJOI7ZmB6P2PjYvtEs=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'FcHPar6J3WYgOeP25nhIL8qCv4eno6UmGSovgBEeQAECzO0nmit4aYUwMMJOI7ZmB6P2PjYvtEs=',\n",
       "   'x-amz-request-id': 'EY66BVF6REZRFJ0Z',\n",
       "   'date': 'Mon, 30 Sep 2024 00:17:47 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"38b2ee8737428c6d3f47a6a861556d6f\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"38b2ee8737428c6d3f47a6a861556d6f\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3r.Bucket(bucket).Object(os.path.join(prefix, 'blazing', bt_file)).put(Body=blazing_text_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/blazing/'\n",
    "batch_input = f's3://{bucket}/{prefix}/blazing/{bt_file}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a batch transformer on the test data. (This step might take a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: blazingtext-2024-09-30-00-17-50-326\n",
      "INFO:sagemaker:Creating transform job with name: blazingtext-2024-09-30-00-17-51-064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Finding and loading model\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Trying to load model from /opt/ml/model/model.bin\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Number of server workers: 8\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\n",
      "\u001b[32m2024-09-30T00:23:19.920:[sagemaker logs]: MaxConcurrentTransforms=8, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Finding and loading model\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Trying to load model from /opt/ml/model/model.bin\u001b[0m\n",
      "\u001b[34m[09/30/2024 00:23:17 INFO 140003308271424] Number of server workers: 8\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[35m[09/30/2024 00:23:17 INFO 140003308271424] Finding and loading model\u001b[0m\n",
      "\u001b[35m[09/30/2024 00:23:17 INFO 140003308271424] Trying to load model from /opt/ml/model/model.bin\u001b[0m\n",
      "\u001b[35m[09/30/2024 00:23:17 INFO 140003308271424] Number of server workers: 8\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[34m[2024-09-30 00:23:17 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[35m[2024-09-30 00:23:17 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[32m2024-09-30T00:23:19.920:[sagemaker logs]: MaxConcurrentTransforms=8, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "CPU times: user 584 ms, sys: 67.1 ms, total: 652 ms\n",
      "Wall time: 6min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bt_transformer = bt_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "bt_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='application/jsonlines',\n",
    "                         split_type='Line')\n",
    "\n",
    "bt_transformer.wait(logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the results from Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.get_object(Bucket=bucket, Key=f'{prefix}/blazing/bt_input.json.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted = pd.read_json(io.BytesIO(obj['Body'].read()),lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[__label__1]</td>\n",
       "      <td>[0.9998536109924311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[__label__0]</td>\n",
       "      <td>[0.885028421878814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[__label__1]</td>\n",
       "      <td>[0.8552113175392151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[__label__1]</td>\n",
       "      <td>[0.9749400615692131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[__label__1]</td>\n",
       "      <td>[0.760517001152038]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                  prob\n",
       "0  [__label__1]  [0.9998536109924311]\n",
       "1  [__label__0]   [0.885028421878814]\n",
       "2  [__label__1]  [0.8552113175392151]\n",
       "3  [__label__1]  [0.9749400615692131]\n",
       "4  [__label__1]   [0.760517001152038]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the results so that you can calculate the confusion matrix and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(label):\n",
    "    label = label[0].replace('__label__','')\n",
    "    return int(label)\n",
    "\n",
    "target_predicted_binary = target_predicted['label'].apply(binary_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity or TPR: 88.5137916838205%\n",
      "Specificity or TNR: 86.69778296382731%\n",
      "Precision: 86.2760834670947%\n",
      "Negative Predictive Value: 88.8755980861244%\n",
      "False Positive Rate: 13.302217036172696%\n",
      "False Negative Rate: 11.486208316179498%\n",
      "False Discovery Rate: 13.723916532905298%\n",
      "Accuracy: 87.58%\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test['label'], target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did BlazingText perform compared to the previous models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using Amazon Comprehend\n",
    "([Go to top](#Lab-4.1:-Implementing-Sentiment-Analysis))\n",
    "\n",
    "In this section, you will use Amazon Comprehend to calculate the sentiment. Amazon Comprehend gives you positive and negative results, and it also shows neutral and mixed results. Amazon Comprehend is a managed service, and it requires less text processing before it's used. You won't need to process any text in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review what the data looks like in the `test` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16591</th>\n",
       "      <td>This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21931</th>\n",
       "      <td>I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22143</th>\n",
       "      <td>There have been several comments already on the site focusing on the \"prestige\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \"Evita\" at that year's Oscars began \"Well, thank God that \"The English Patient\" had no songs in it.\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \"Howard's End\" proved that one of the hardest things that an actor can do is make the portrayal of \"goodness\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \"old bookseller.\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \"Dennis Hoey\" by kidnapping Tobel. The only clue left by Tobel is a list of \"dancing men.\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "16591                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.   \n",
       "21931                                                                                                                                                                                                                                                             I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.   \n",
       "22143  There have been several comments already on the site focusing on the \"prestige\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \"Evita\" at that year's Oscars began \"Well, thank God that \"The English Patient\" had no songs in it.\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \"Howard's End\" proved that one of the hardest things that an actor can do is make the portrayal of \"goodness\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.   \n",
       "1133                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!   \n",
       "10413                                                                                                                                                                                                                                              Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \"old bookseller.\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \"Dennis Hoey\" by kidnapping Tobel. The only clue left by Tobel is a list of \"dancing men.\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.   \n",
       "\n",
       "       label  \n",
       "16591      1  \n",
       "21931      0  \n",
       "22143      1  \n",
       "1133       1  \n",
       "10413      1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Amazon Comprehend can be as straightforward as making an API call.\n",
    "\n",
    "The following cell outputs the first five results from Amazon Comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE - This is a charming movie starring everyone's favorite cartoon chipmunks. In this feature we follow the band of rodents on an unforgettable balloon race around the world. Although there are lows, including an orphan penguin, all in all it's a great family film.\n",
      "NEGATIVE - I really should have learned more about this movie before renting it. It was one of those movies where you keep watching it figuring it's got to get better. Then, when it ends, you feel stupid for having wasted precious time in your life that you can never get back. Ice-T did his bad guy thing and, well, that was the highlight of the evening. The pictures of the shuttle looks like it was done with a little toy inside of a box and the spacewalking scenes were funny because you could see the strings attached to the space suits. The script was lacking and the car chase scene with the guy bleeding and going unconscious was incredible because he drove better than I could have on one of my best days. All in all, I have seen worse but this sure isn't one I'd recommend or want to remember.\n",
      "POSITIVE - There have been several comments already on the site focusing on the \"prestige\" feel of the film - and there is a lot of heavy-weight talent on show: from Fiennes and Scott-Thomas to the magnificently rendered design and scoring, to the masterly direction. No wonder that Andrew Lloyd Webber's acceptance speech for \"Evita\" at that year's Oscars began \"Well, thank God that \"The English Patient\" had no songs in it.\" Writing of Oscar winners takes me to Juliette Binoche, who, in a stellar cast, gives a beautiful performance. It is heartening to see that the dynamics which seem to influence the award for Best Actor (often going to showy pyrotechnic display) aren't at work in the female categories. Just as Emma Thompson's hugely well-deserved Oscar for her portrayal of Margaret Schlegel in \"Howard's End\" proved that one of the hardest things that an actor can do is make the portrayal of \"goodness\" involving, so Binoche's win proved that it could be that - and seriously sexy. Her performance in this terrific film is a thing of beauty.\n",
      "POSITIVE - My wife and I struggle to find movies like this that are clean and yet enjoyable for adults. If you can't find a cinema that is playing it, call your cinema and request it. Bravo, Five Sisters Productions for courage, tenacity and creative endeavor!\n",
      "NEUTRAL - Basil Rathbone and Nigel Bruce return as Sherlock Holmes and Dr. Watson in this superior tale of Holmes battling the 3rd Reich and the mastermind genius of Professor Moriarty. The film opens up in Switzerland as Holmes is in disguise as an \"old bookseller.\" He must bring Dr. Tobel and the Tobel Bomb Site to England before the Germans can kidnap Tobel. Holmes succeeds and the Germans recuit the evil Professor. Moriarty manages to outwit Scotland yard and LeStrad \"Dennis Hoey\" by kidnapping Tobel. The only clue left by Tobel is a list of \"dancing men.\" Who will break the hidden code of dancing men, Holmes or Moriarty first? Can Holmes prevent the bomb site from falling into the German hands thereby saving England from the precision bombing techniques developed by Tobel's bomb site? Watch and enjoy.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "comprehend = boto3.client(service_name='comprehend')\n",
    "for n in range(5):\n",
    "    text = test.iloc[n]['text']\n",
    "    response = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n",
    "    sentiment = response['Sentiment']\n",
    "    print(f'{sentiment} - {text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start a prediction job to process multiple items. The input must be formatted as a single input per line, and uploaded to Amazon S3. The text has a maximum size of 5120, so the `str.slice(0,5000)` function is used to trim long text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded input to s3://c127808a3228842l7775723t1w505704594257-labbucket-eutc1xxyq9qx/lab41/comprehend/comprehend_input.csv\n"
     ]
    }
   ],
   "source": [
    "# Upload test file minus label to S3\n",
    "def upload_comprehend_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "comprehend_file = 'comprehend_input.csv'\n",
    "upload_comprehend_s3_csv(comprehend_file, 'comprehend', test['text'].str.slice(0,5000))\n",
    "test_url = f's3://{bucket}/{prefix}/comprehend/{comprehend_file}'\n",
    "print(f'Uploaded input to {test_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the data is uploaded to Amazon S3, you start the job by using the `start_sentiment_detection_jon` function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Configuring the Amazon Comprehend job parameters\n",
    "\n",
    "In the next cell, configure the Amazon Comprehend job parameters. \n",
    "- In __input_data_config__ - \n",
    "  - **S3Uri**: Replace *`<S3_INPUT_GOES_HERE>`* with the `test_uri` that was defined previously\n",
    "  - **InputFormat**: Replace *`<INPUT_FORMAT_GOES_HERE>`* with `ONE_DOC_PER_LINE`\n",
    "- In __output_data-config__ -  \n",
    "  - **S3Uri**: Replace *`<S3_OUTPUT_GOES_HERE>`*  with the `s3_output_location`\n",
    "  - **data_access_role_arn**: Replace *`data_acess_role_arn`* with the Amazon Resource Name (ARN) of the IAM Role ComprehendDataAccessRole.  To get the role, ARN go to the IAM console and choose Roles in the left navigation menu.  You will see all roles listed and from there you can find ComprehendDataAccessRole.  Choose that role, and copy the ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config={\n",
    "    'S3Uri': 'S3_INPUT_GOES_HERE',\n",
    "    'InputFormat': 'INPUT_FORMAT_GOES_HERE'\n",
    "},\n",
    "\n",
    "output_data_config={\n",
    "    'S3Uri': 'S3_OUTPUT_GOES_HERE'\n",
    "},\n",
    "data_access_role_arn = 'arn:aws:iam::505704594257:role/service-role/c127808a3228842l7775723t1w-ComprehendDataAccessRole-5kXhibOR3Xp2'\n",
    "\n",
    "### BEGIN_SOLUTION\n",
    "input_data_config={\n",
    "    'S3Uri': test_url,\n",
    "    'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "}\n",
    "output_data_config={\n",
    "    'S3Uri': s3_output_location\n",
    "}\n",
    "data_access_role_arn = 'arn:aws:iam::505704594257:role/service-role/c127808a3228842l7775723t1w-ComprehendDataAccessRole-5kXhibOR3Xp2'\n",
    "### END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you defined the job parameters, start the sentiment detection job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMITTED\n"
     ]
    }
   ],
   "source": [
    "response = comprehend.start_sentiment_detection_job(\n",
    "    InputDataConfig=input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    DataAccessRoleArn=data_access_role_arn,\n",
    "    JobName='movie_sentiment',\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "print(response['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will loop until the job is completed. (This step might take a few minutes to complete.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................COMPLETED\n",
      "CPU times: user 604 ms, sys: 46.5 ms, total: 650 ms\n",
      "Wall time: 10min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "job_id = response['JobId']\n",
    "while True:\n",
    "    job_status=(comprehend.describe_sentiment_detection_job(JobId=job_id))\n",
    "    if job_status['SentimentDetectionJobProperties']['JobStatus'] in ['COMPLETED','FAILED']:\n",
    "        break            \n",
    "    else:\n",
    "        print('.', end='')\n",
    "    time.sleep(15)\n",
    "print((comprehend.describe_sentiment_detection_job(JobId=job_id))['SentimentDetectionJobProperties']['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the job is complete, you can return the details from the job by calling the `describe_sentiment_detection_job` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SentimentDetectionJobProperties': {'JobId': '8efb44734dbb0f6b93f6bdf9ace3f5bd', 'JobArn': 'arn:aws:comprehend:us-east-1:505704594257:sentiment-detection-job/8efb44734dbb0f6b93f6bdf9ace3f5bd', 'JobName': 'movie_sentiment', 'JobStatus': 'COMPLETED', 'SubmitTime': datetime.datetime(2024, 9, 30, 0, 29, 58, 705000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 30, 0, 40, 6, 607000, tzinfo=tzlocal()), 'InputDataConfig': {'S3Uri': 's3://c127808a3228842l7775723t1w505704594257-labbucket-eutc1xxyq9qx/lab41/comprehend/comprehend_input.csv', 'InputFormat': 'ONE_DOC_PER_LINE'}, 'OutputDataConfig': {'S3Uri': 's3://c127808a3228842l7775723t1w505704594257-labbucket-eutc1xxyq9qx/lab41/output/505704594257-SENTIMENT-8efb44734dbb0f6b93f6bdf9ace3f5bd/output/output.tar.gz'}, 'LanguageCode': 'en', 'DataAccessRoleArn': 'arn:aws:iam::505704594257:role/service-role/c127808a3228842l7775723t1w-ComprehendDataAccessRole-5kXhibOR3Xp2'}, 'ResponseMetadata': {'RequestId': '2bd8aa6c-c167-4563-ae18-2df9402b2e9c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2bd8aa6c-c167-4563-ae18-2df9402b2e9c', 'content-type': 'application/x-amz-json-1.1', 'content-length': '806', 'date': 'Mon, 30 Sep 2024 00:40:17 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "output=(comprehend.describe_sentiment_detection_job(JobId=job_id))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **OutputDataConfig** section, you should see the `S3Uri`. Extracting that URI will give you the file that you must download from Amazon S3. You can use the results to calculate metrics in the same way that you calculated the results from a batch transformation by using an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_output_file = output['SentimentDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "comprehend_bucket, comprehend_key = comprehend_output_file.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "s3r = boto3.resource('s3')\n",
    "s3r.meta.client.download_file(comprehend_bucket, comprehend_key, 'output.tar.gz')\n",
    "\n",
    "# Extract the tar file\n",
    "import tarfile\n",
    "tf = tarfile.open('output.tar.gz')\n",
    "tf.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted file should be named __output__. Read the the lines in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = ''\n",
    "with open ('output', \"r\") as myfile:\n",
    "    data = myfile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the lines to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for line in data:\n",
    "    json_data = json.loads(line)\n",
    "    results.append([json_data['Line'],json_data['Sentiment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the array to a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MIXED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment\n",
       "index          \n",
       "1      NEGATIVE\n",
       "2       NEUTRAL\n",
       "4       NEUTRAL\n",
       "6       NEUTRAL\n",
       "7         MIXED"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.DataFrame.from_records(results, index='index', columns=['index','sentiment'])\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results contain **NEGATIVE**, **POSITIVE**, **NEUTRAL**, and **MIXED** results instead of numerical values. To compare these results to your test data, they can be mapped to numerical values, as shown in the following cell. The index in the returned results is also out of order. The `sort_index` function should fix this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10249/2424558615.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  c['sentiment']=c['sentiment'].replace(class_mapper)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "index           \n",
       "0              1\n",
       "1              0\n",
       "2              2\n",
       "3              1\n",
       "4              2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapper = {'NEGATIVE':0, 'POSITIVE':1, 'NEUTRAL':2, 'MIXED':3}\n",
    "c['sentiment']=c['sentiment'].replace(class_mapper)\n",
    "c = c.sort_index()\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list to compare for Amazon Comprehend\n",
    "test_2 = test.reset_index()\n",
    "test_3 = test_2.sort_index()\n",
    "test_labels = test_3.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display a confusion matrix by using the `plot_confusion_matrix` function. Because Amazon Comprehend also includes __mixed__ and __neutral__ in the results, the chart will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_labels, c['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existing function to print metrics won't work because you have too many data dimensions. The following code cell will calculate the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity or TPR: 90.92627599243856%\n",
      "Specificity or TNR: 88.80097382836276%\n",
      "Precision: 88.69084204056546%\n",
      "Negative Predictive Value: 91.01684341859014%\n",
      "False Positive Rate: 11.199026171637248%\n",
      "False Negative Rate: 9.073724007561438%\n",
      "False Discovery Rate: 11.309157959434541%\n",
      "Accuracy: 89.84520123839009%\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, c['sentiment'])\n",
    "\n",
    "TN = cm[0,0]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "TP = cm[1,1]\n",
    "\n",
    "Sensitivity  = float(TP)/(TP+FN)*100\n",
    "# Specificity or true negative rate\n",
    "Specificity  = float(TN)/(TN+FP)*100\n",
    "# Precision or positive predictive value\n",
    "Precision = float(TP)/(TP+FP)*100\n",
    "# Negative predictive value\n",
    "NPV = float(TN)/(TN+FN)*100\n",
    "# Fall out or false positive rate\n",
    "FPR = float(FP)/(FP+TN)*100\n",
    "# False negative rate\n",
    "FNR = float(FN)/(TP+FN)*100\n",
    "# False discovery rate\n",
    "FDR = float(FP)/(TP+FP)*100\n",
    "# Overall accuracy\n",
    "ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "\n",
    "print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "print(f\"Specificity or TNR: {Specificity}%\") \n",
    "print(f\"Precision: {Precision}%\")   \n",
    "print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "print( f\"False Positive Rate: {FPR}%\") \n",
    "print(f\"False Negative Rate: {FNR}%\")  \n",
    "print(f\"False Discovery Rate: {FDR}%\" )\n",
    "print(f\"Accuracy: {ACC}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this lab, and you can now end the lab by following the lab guide instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*©2023 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. All trademarks are the property of their owners.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "metadata": {
   "interpreter": {
    "hash": "12bdb53ebf8de4a8c3e84b62f6391946884c7c7585d9344b706f290a85145ccc"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
